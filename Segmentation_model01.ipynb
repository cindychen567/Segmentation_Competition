{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"V4.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyOjOm1hQqPfnhjX1wMwaHVm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ua5nrj3yeJZw","executionInfo":{"status":"ok","timestamp":1653630774456,"user_tz":-480,"elapsed":436,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"51d3b823-70af-490b-aa0f-7094b164d553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri May 27 05:52:53 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P0    39W / 250W |  16157MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip install -q \"monai[tqdm, nibabel, qdown, ignite]\" \"itk\" \"itkwidgets\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x9Emxy-FDJ3e","executionInfo":{"status":"ok","timestamp":1659678189452,"user_tz":-480,"elapsed":55638,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"218e9910-d267-4495-9333-d40e61412908"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 990 kB 2.7 MB/s \n","\u001b[K     |████████████████████████████████| 3.4 MB 51.5 MB/s \n","\u001b[K     |████████████████████████████████| 95.3 MB 34 kB/s \n","\u001b[K     |████████████████████████████████| 16.6 MB 27.5 MB/s \n","\u001b[K     |████████████████████████████████| 54.5 MB 1.3 MB/s \n","\u001b[K     |████████████████████████████████| 20.3 MB 11.7 MB/s \n","\u001b[K     |████████████████████████████████| 15.0 MB 33.2 MB/s \n","\u001b[K     |████████████████████████████████| 70.6 MB 7.7 kB/s \n","\u001b[K     |████████████████████████████████| 862 kB 56.4 MB/s \n","\u001b[K     |████████████████████████████████| 2.5 MB 41.0 MB/s \n","\u001b[K     |████████████████████████████████| 508 kB 53.5 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 62.3 MB/s \n","\u001b[K     |████████████████████████████████| 11.2 MB 44.6 MB/s \n","\u001b[K     |████████████████████████████████| 944 kB 57.3 MB/s \n","\u001b[33mWARNING: monai 0.9.1 does not provide the extra 'qdown'\u001b[0m\n","\u001b[K     |████████████████████████████████| 259 kB 60.4 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPwFs73SCtDN","executionInfo":{"status":"ok","timestamp":1659678384004,"user_tz":-480,"elapsed":29435,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"1f7c0cd3-3f10-42fe-f09a-163c90a5d106"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","os.chdir(\"/content/drive/MyDrive/Deep Learning/\")"]},{"cell_type":"markdown","source":["## Import Packages"],"metadata":{"id":"6MOy_OFdDCej"}},{"cell_type":"code","source":["import logging\n","import os\n","import sys\n","import tempfile\n","from glob import glob\n","import time\n","\n","import torch\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import matplotlib.pyplot as plt\n","\n","import monai\n","from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n","from monai.inferers import sliding_window_inference, SimpleInferer\n","from monai.metrics import DiceMetric\n","from monai.transforms import (\n","    Activations,\n","    AddChanneld,\n","    AsDiscrete,\n","    Compose,\n","    LoadImaged,\n","    RandCropByPosNegLabeld,\n","    RandAdjustContrastd,\n","    RandRotate90d,\n","    ScaleIntensityd,\n","    EnsureTyped,\n","    EnsureType,\n","    AsChannelFirstd,\n","    AsChannelLast,\n","    Resized,\n","    RandScaleCropd,\n","    RandRotated,\n","    Rotated,\n","    SaveImage,\n",")\n","from monai.visualize import plot_2d_or_3d_image"],"metadata":{"id":"MhT2egl-C_k_","executionInfo":{"status":"ok","timestamp":1659678391706,"user_tz":-480,"elapsed":7707,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Check Monai Configurations"],"metadata":{"id":"CojDKiWFEUbm"}},{"cell_type":"code","source":["monai.config.print_config()\n","logging.basicConfig(stream=sys.stdout, level=logging.INFO)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6X67pukETI1","executionInfo":{"status":"ok","timestamp":1659678391707,"user_tz":-480,"elapsed":18,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"ed8a5af2-d747-4f69-9e1f-26e892ceea66"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["MONAI version: 0.9.1\n","Numpy version: 1.21.6\n","Pytorch version: 1.12.0+cu113\n","MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n","MONAI rev id: 356d2d2f41b473f588899d705bbc682308cee52c\n","MONAI __file__: /usr/local/lib/python3.7/dist-packages/monai/__init__.py\n","\n","Optional dependencies:\n","Pytorch Ignite version: 0.4.9\n","Nibabel version: 3.0.2\n","scikit-image version: 0.18.3\n","Pillow version: 7.1.2\n","Tensorboard version: 2.8.0\n","gdown version: 4.4.0\n","TorchVision version: 0.13.0+cu113\n","tqdm version: 4.64.0\n","lmdb version: 0.99\n","psutil version: 5.4.8\n","pandas version: 1.3.5\n","einops version: NOT INSTALLED or UNKNOWN VERSION.\n","transformers version: NOT INSTALLED or UNKNOWN VERSION.\n","mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n","pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n","\n","For details about installing the optional dependencies, please visit:\n","    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n","\n"]}]},{"cell_type":"markdown","source":["## Process VGH Data"],"metadata":{"id":"Qg0zmt1uEdz8"}},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/Deep Learning/SEG_Train_Datasets/dataset/\""],"metadata":{"id":"WPkK5Z3iEbAx","executionInfo":{"status":"ok","timestamp":1659678751949,"user_tz":-480,"elapsed":361,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["-obtain train data list"],"metadata":{"id":"fGVeHkLpE_Ht"}},{"cell_type":"code","source":["tempdir = data_path + \"train/image/\"\n","train_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n","\n","tempdir = data_path + \"train/msk_img/\"\n","train_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n","print(f\" {len(train_images)} train_images and {len(train_segs)} train_segs\")\n","train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[:], train_segs[:])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtOdS2pjFEH-","executionInfo":{"status":"ok","timestamp":1659678760915,"user_tz":-480,"elapsed":7342,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"f49f3737-ccd4-4819-9751-29b9fa83ee2d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[" 842 train_images and 842 train_segs\n"]}]},{"cell_type":"markdown","source":["-obtain validation data list"],"metadata":{"id":"5B__YmYMFIIc"}},{"cell_type":"code","source":["tempdir = data_path + \"validation/image/\"\n","valid_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n","\n","tempdir = data_path + \"validation/msk_img/\"\n","valid_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n","print(f\" {len(valid_images)} valid_images and {len(valid_segs)} valid_segs\")\n","\n","val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(valid_images[:], valid_segs[:])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnDMK7uCFLTS","executionInfo":{"status":"ok","timestamp":1659678762075,"user_tz":-480,"elapsed":1165,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"e944f197-3317-44f6-eb1c-04546de43eeb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":[" 105 valid_images and 105 valid_segs\n"]}]},{"cell_type":"markdown","source":["## Define Transform for image and Segmentation"],"metadata":{"id":"pRvfQWsgFS5Q"}},{"cell_type":"code","source":["# define transforms for image and segmentation\n","train_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"img\", \"seg\"]),\n","        AddChanneld(keys=[\"seg\"]),        \n","        AsChannelFirstd(keys=[\"img\"]),\n","        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n","        #RandScaleCropd(keys=[\"img\", \"seg\"],roi_scale=0.5,max_roi_scale=1.5),\n","        #RandRotated(keys=[\"img\", \"seg\"],range_x=3.14),\n","        RandAdjustContrastd(keys=[\"img\"], prob=0.1, gamma=(0.5, 4.5)),\n","        #RandCropByPosNegLabeld(\n","        #    keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[800, 800], pos=1, neg=1, num_samples=4\n","        #),\n","        # RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5),\n","        Resized(keys=[\"img\", \"seg\"], spatial_size=[1600, 800]),\n","        EnsureTyped(keys=[\"img\", \"seg\"]),\n","    ]\n",")\n","val_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"img\", \"seg\"]),\n","        AddChanneld(keys=[\"seg\"]),        \n","        AsChannelFirstd(keys=[\"img\"]),\n","        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n","        Resized(keys=[\"img\", \"seg\"], spatial_size=[1696, 928]),\n","        EnsureTyped(keys=[\"img\", \"seg\"]),\n","    ]\n",")"],"metadata":{"id":"fX-EPwmrFSGz","executionInfo":{"status":"ok","timestamp":1659678762076,"user_tz":-480,"elapsed":5,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Check and Visualize the Transform Results"],"metadata":{"id":"1PyrQXGOFdhZ"}},{"cell_type":"code","source":["# define dataset, data loader\n","check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)"],"metadata":{"id":"Zjqh3iwbFcvv","executionInfo":{"status":"ok","timestamp":1659678768976,"user_tz":-480,"elapsed":306,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["batch = 4\n","check_loader = DataLoader(check_ds, batch_size=batch, num_workers=12, collate_fn=list_data_collate)\n","check_data = monai.utils.misc.first(check_loader)\n","print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n","\n","\n","# import matplotlib.pyplot as plt\n","\n","# plt.figure(\"visualize\",(16,64))\n","# for i in range(batch):\n","#     plt.subplot(8,2,2*i+1)    \n","#     plt.imshow(check_data[\"img\"][i].permute(1,2,0))\n","#     plt.subplot(8,2,2*i+2)\n","#     plt.imshow(check_data[\"seg\"][i].permute(1,2,0).squeeze())"],"metadata":{"id":"4JMfqQmAunvV","executionInfo":{"status":"ok","timestamp":1659678805033,"user_tz":-480,"elapsed":34386,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89b1dd96-7233-43ff-975a-540205e0f888"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]},{"output_type":"stream","name":"stdout","text":["(4, 3, 1600, 800) (4, 1, 1600, 800)\n"]}]},{"cell_type":"markdown","source":["## Create DataLoader for Train and Validation Data"],"metadata":{"id":"YjCn5HAXwmeM"}},{"cell_type":"code","source":["# create a training data loader\n","train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n","# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n","train_loader = DataLoader(\n","    train_ds,\n","    batch_size=2,\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=list_data_collate,\n","    pin_memory=torch.cuda.is_available(),\n",")\n","\n","# create a validation data loader\n","val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n","val_loader = DataLoader(val_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)"],"metadata":{"id":"eBxMo6tqur7Q","executionInfo":{"status":"ok","timestamp":1659678805034,"user_tz":-480,"elapsed":15,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"759b5910-a734-423c-fae9-441b0a31d3ce"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]}]},{"cell_type":"markdown","source":["## Define metric and post- processing"],"metadata":{"id":"Le71Z01wwyXM"}},{"cell_type":"code","source":["dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n","post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n","post_trans_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])"],"metadata":{"id":"5oPhTRCfwxD3","executionInfo":{"status":"ok","timestamp":1659678805035,"user_tz":-480,"elapsed":8,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Built Model"],"metadata":{"id":"OBdAVVWJw6IQ"}},{"cell_type":"code","source":["# create UNet, DiceLoss and Adam optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = monai.networks.nets.DynUNet(\n","    spatial_dims=2,\n","    in_channels=3,\n","    out_channels=1,\n","    kernel_size=(3,3,3,3),\n","    strides=(1,2,2,2),\n","    upsample_kernel_size=(2,2,2,2),\n","    res_block=True,\n","    trans_bias=True,\n",").to(device)\n","\n","\n","loss_function = monai.losses.DiceLoss(sigmoid=True)\n","optimizer = torch.optim.Adam(model.parameters(), 1e-5)"],"metadata":{"id":"7HDrzH7Nw5So","executionInfo":{"status":"ok","timestamp":1659678811995,"user_tz":-480,"elapsed":6966,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!pip install netron"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tcjzuMjkHpy","executionInfo":{"status":"ok","timestamp":1659678819104,"user_tz":-480,"elapsed":6357,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"689094be-3676-47da-bb12-536eb7286c84"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting netron\n","  Downloading netron-5.9.8-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 3.2 MB/s \n","\u001b[?25hInstalling collected packages: netron\n","Successfully installed netron-5.9.8\n"]}]},{"cell_type":"code","source":["import netron\n","\n","onnx_path = \"model.onnx\"\n","input_dummy = torch.randn(4,3,1600,800).to(device)\n","model.eval()\n","\n","torch.onnx.export(model , input_dummy , onnx_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBc3nXMukK8L","executionInfo":{"status":"ok","timestamp":1659678973324,"user_tz":-480,"elapsed":1683,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"81d59a4c-44c9-4868-8048-ceb4cac03584"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["ONNX export mode is set to inference mode, but operator instance_norm is set to training  mode. The operators will be exported in training , as specified by the functional operator.\n"]}]},{"cell_type":"code","source":["netron.start(\"model.onnx\")"],"metadata":{"id":"gX9Z3tp0k3sb","executionInfo":{"status":"ok","timestamp":1659678989865,"user_tz":-480,"elapsed":6,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"24908571-ae91-4ca2-c55d-83960a02bc59","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Serving 'model.onnx' at http://localhost:8081\n"]},{"output_type":"execute_result","data":{"text/plain":["('localhost', 8081)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Create Visualize Function"],"metadata":{"id":"oS8Aw8OfxHVx"}},{"cell_type":"code","source":["def visualize(**images):\n","    \"\"\"PLot images in one row.\"\"\"\n","    n = len(images)\n","    plt.figure(figsize=(16, 16))\n","    for i, (name, image) in enumerate(images.items()):\n","        plt.subplot(1, n, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.title(' '.join(name.split('_')).title())\n","        plt.imshow(image)\n","    plt.show()"],"metadata":{"id":"DmUetu5lw_9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Training Parameters and Start training"],"metadata":{"id":"GX9p4aYnxPo0"}},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict0525.pth\"))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWHEFg2m7xPj","executionInfo":{"status":"ok","timestamp":1653629865571,"user_tz":-480,"elapsed":3238,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"0a065c4b-2e3b-4834-d3ab-ff71003ac687"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DynUNet(\n","  (input_block): UnetResBlock(\n","    (conv1): Convolution(\n","      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv2): Convolution(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv3): Convolution(\n","      (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","    (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","  )\n","  (downsamples): ModuleList(\n","    (0): UnetResBlock(\n","      (conv1): Convolution(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      )\n","      (conv2): Convolution(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv3): Convolution(\n","        (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","      (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    )\n","    (1): UnetResBlock(\n","      (conv1): Convolution(\n","        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      )\n","      (conv2): Convolution(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv3): Convolution(\n","        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","      (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    )\n","  )\n","  (bottleneck): UnetResBlock(\n","    (conv1): Convolution(\n","      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    )\n","    (conv2): Convolution(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv3): Convolution(\n","      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","    (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","  )\n","  (upsamples): ModuleList(\n","    (0): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","    (1): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","    (2): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","  )\n","  (output_block): UnetOutBlock(\n","    (conv): Convolution(\n","      (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (skip_layers): DynUNetSkipLayer(\n","    (downsample): UnetResBlock(\n","      (conv1): Convolution(\n","        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv2): Convolution(\n","        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv3): Convolution(\n","        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","      (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    )\n","    (next_layer): DynUNetSkipLayer(\n","      (downsample): UnetResBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv3): Convolution(\n","          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","      (next_layer): DynUNetSkipLayer(\n","        (downsample): UnetResBlock(\n","          (conv1): Convolution(\n","            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          )\n","          (conv2): Convolution(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (conv3): Convolution(\n","            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          )\n","          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","          (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","        (next_layer): UnetResBlock(\n","          (conv1): Convolution(\n","            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          )\n","          (conv2): Convolution(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (conv3): Convolution(\n","            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          )\n","          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","          (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","        (upsample): UnetUpBlock(\n","          (transp_conv): Convolution(\n","            (conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (conv_block): UnetBasicBlock(\n","            (conv1): Convolution(\n","              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            )\n","            (conv2): Convolution(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            )\n","            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","            (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","            (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          )\n","        )\n","      )\n","      (upsample): UnetUpBlock(\n","        (transp_conv): Convolution(\n","          (conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","        )\n","        (conv_block): UnetBasicBlock(\n","          (conv1): Convolution(\n","            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (conv2): Convolution(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","          (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","      )\n","    )\n","    (upsample): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["#### start a typical PyTorch training\n","total_epochs = 40\n","val_interval = 1\n","best_metric = 0\n","best_metric_epoch = -1\n","epoch_loss_values = list()\n","metric_values = list()\n","writer = SummaryWriter()\n","for epoch in range(total_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{total_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    for batch_data in train_loader:\n","        step += 1\n","        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        \n","        outputs=[post_trans(i) for i in decollate_batch(outputs)]\n","        labels=[post_trans_label(i) for i in decollate_batch(labels)] \n","        dice_metric(y_pred=outputs, y=labels)\n","        \n","        \n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n","        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n","\n","    metric = dice_metric.aggregate().item()\n","    dice_metric.reset()\n","    #print(\"current training dice score: {:.4f} \".format(metric))\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n","    print(f\"{local_time} epoch {epoch + 1} average loss: {epoch_loss:.4f} dice score:{metric}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            val_images = None\n","            val_labels = None\n","            val_outputs = None\n","            show_val = True\n","            for val_data in val_loader:\n","                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n","                roi_size = (1600, 800)\n","                sw_batch_size = 4\n","                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model) \n","                \n","                #if show_val:\n","                #    visualize( \n","                #        image=val_images[0].cpu().permute(1,2,0), \n","                #        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n","                #        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n","                #    )        \n","                \n","                \n","                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n","                val_labels = [post_trans_label(i) for i in decollate_batch(val_labels)]\n","                # compute metric for current iteration\n","                dice_metric(y_pred=val_outputs, y=val_labels)\n","\n","                # if show_val:\n","                #     visualize( \n","                #         image=val_images[0].cpu().permute(1,2,0), \n","                #         ground_truth_mask=val_labels[0].cpu().permute(1,2,0).squeeze(), \n","                #         predicted_mask=val_outputs[0].cpu().permute(1,2,0).squeeze()\n","                #     )                                      \n","                \n","                show_val = False\n","                \n","\n","            # aggregate the final mean dice result\n","            metric = dice_metric.aggregate().item()\n","            # reset the status for next validation round\n","            dice_metric.reset()            \n","            metric_values.append(metric)\n","            if metric > best_metric:\n","                best_metric = metric\n","                best_metric_epoch = epoch + 1\n","                torch.save(model.state_dict(), \"best_metric_model_segmentation2d_dict0527.pth\")\n","                print(\"saved new best metric model\")\n","            print(\n","                \"current epoch: {} current val mean dice score: {:.4f} best val mean dice score: {:.4f} at epoch {}\".format(\n","                    epoch + 1, metric, best_metric, best_metric_epoch\n","                )\n","            )\n","            writer.add_scalar(\"val_mean_dice score\", metric, epoch + 1)\n","            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n","            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n","            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n","            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n","            \n","\n","print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","writer.close()\n","\n","\n","torch.save(model.state_dict(), \"Final_model_40_epoches_segmentation2d_dict0527.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"MGwB8ssaxPHK","executionInfo":{"status":"error","timestamp":1653629871593,"user_tz":-480,"elapsed":3006,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"358ebe7f-30e6-42d9-c745-d01eb07da705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","epoch 1/40\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-23ef2be51cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/nets/dynunet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_supervision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/nets/dynunet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdownout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mnextout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mupout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/blocks/dynunet_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 15.90 GiB total capacity; 14.18 GiB already allocated; 123.75 MiB free; 14.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"markdown","source":["-obtain test datalist"],"metadata":{"id":"aB-Hc0M-QcQu"}},{"cell_type":"code","source":["# Load testing files\n","tempdir = data_path + \"test/image/\"\n","test_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n","\n","tempdir = data_path + \"test/msk_img/\"\n","test_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n","\n","print(f\" {len(test_images)} test_images and {len(test_segs)} test_segs\")\n","# print(f\" {len(test_images)} test_images\")\n","\n","test_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(test_images[:], test_segs[:])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eje5TZIlxf3V","executionInfo":{"status":"ok","timestamp":1653399076970,"user_tz":-480,"elapsed":6216,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"ad6f0f55-0b66-47a7-c5b3-960d78f4f6d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 106 test_images and 106 test_segs\n"]}]},{"cell_type":"code","source":["test_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"img\", \"seg\"]),\n","        \n","        AddChanneld(keys=[\"seg\"]),        \n","        AsChannelFirstd(keys=[\"img\"]),\n","\n","        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n","        #Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n","        EnsureTyped(keys=[\"img\", \"seg\"]),\n","    ]\n",")\n","test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)"],"metadata":{"id":"oV4h1ldOQ54x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3cQD7KQRN1R","executionInfo":{"status":"ok","timestamp":1653399167553,"user_tz":-480,"elapsed":630,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"196a90f5-9411-4190-b78d-eddb7c2069eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict.pth\"))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuJ0CytGQ6ss","executionInfo":{"status":"ok","timestamp":1653399614639,"user_tz":-480,"elapsed":366,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"0a12f788-6bb0-42d8-c9eb-76d5ad9e7332"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["with torch.no_grad():\n","    for test_data in test_loader:\n","        test_images, test_labels = test_data[\"img\"].to(device), test_data[\"seg\"].to(device)\n","        # define sliding window size and batch size for windows inference\n","        roi_size = (800, 800)\n","        sw_batch_size = 4\n","        test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n","\n","        # visualize( \n","        #     image=test_images[0].cpu().permute(1,2,0), \n","        #     ground_truth_mask=test_labels[0].cpu().permute(1,2,0).squeeze(), \n","        #     predicted_mask=test_outputs[0].squeeze().cpu().numpy().round()\n","        # )           \n","        # saverGT(test_labels[0].cpu())\n","        # saverIM(test_images[0].cpu())        \n","        # saverPD(test_outputs[0].cpu())\n","        \n","        test_outputs = [post_trans(i) for i in decollate_batch(test_outputs)]\n","        test_labels = [post_trans(i) for i in decollate_batch(test_labels)]\n","        \n","        \n","                \n","        # compute metric for current iteration\n","        dice_metric(y_pred=test_outputs, y=test_labels)\n","        #for test_output in test_outputs:            \n","        #    saver(test_output*255)\n","    # aggregate the final mean dice result    \n","    print(\"evaluation metric:\", dice_metric.aggregate().item())\n","    # reset the status\n","    dice_metric.reset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7C3L4e_Q95O","executionInfo":{"status":"ok","timestamp":1653399646322,"user_tz":-480,"elapsed":29867,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"7fdb42e1-4d5e-4f48-d741-654b68f8c7a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]},{"output_type":"stream","name":"stdout","text":["evaluation metric: 0.04734683409333229\n"]}]},{"cell_type":"markdown","source":["## Prediction on Public Image"],"metadata":{"id":"IODir1ClSWZ7"}},{"cell_type":"markdown","source":["-obtain data list"],"metadata":{"id":"ucgFhTfZScs_"}},{"cell_type":"code","source":["public_path = \"/content/drive/MyDrive/Deep Learning/\""],"metadata":{"id":"XOgzJnQ7SmJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load testing files\n","tempdir = public_path + \"Public_Image/\"\n","pred_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n","\n","#tempdir = data_path + \"Valid_Masks/\"\n","#test_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n","\n","#print(f\" {len(test_images)} test_images and {len(test_segs)} test_segs\")\n","print(f\" {len(pred_images)} pred_images\")\n","\n","pred_files = [{\"img\": img} for img in zip(pred_images[:])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSM71v6kSWAM","executionInfo":{"status":"ok","timestamp":1653593341638,"user_tz":-480,"elapsed":7,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"58519804-321a-4587-fcd6-022938085f60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 131 pred_images\n"]}]},{"cell_type":"markdown","source":["## Define Transform for Prediction data"],"metadata":{"id":"0_FGvktaTESU"}},{"cell_type":"code","source":["# define transforms for image and segmentation\n","pred_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"img\"]),\n","        \n","        #Rotated(keys=[\"img\"], angle=90),\n","        AsChannelFirstd(keys=[\"img\"]),\n","\n","        ScaleIntensityd(keys=[\"img\"]),\n","        #Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n","        EnsureTyped(keys=[\"img\"]),\n","    ]\n",")\n","pred_ds = monai.data.Dataset(data=pred_files, transform=pred_transforms)\n","\n","\n","post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"],"metadata":{"id":"iLmavxmwR4QM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save Images"],"metadata":{"id":"0NOWD6R13b4N"}},{"cell_type":"code","source":["pred_loader = DataLoader(pred_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n","saverPD = SaveImage(output_dir=\"./prediction0526_2\", output_ext=\".png\", output_postfix=\"PD\",scale=255,separate_folder=False)"],"metadata":{"id":"tIBP5QTb3Zxu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"5GedmzZZ3sx1"}},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict0526_2.pth\" ))\n","model.eval()"],"metadata":{"id":"FBvVSZAD3obu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653593360969,"user_tz":-480,"elapsed":723,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}},"outputId":"cea0cf7d-ca42-4255-c239-b3253440782f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DynUNet(\n","  (input_block): UnetResBlock(\n","    (conv1): Convolution(\n","      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv2): Convolution(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv3): Convolution(\n","      (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","    (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","  )\n","  (downsamples): ModuleList(\n","    (0): UnetResBlock(\n","      (conv1): Convolution(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      )\n","      (conv2): Convolution(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv3): Convolution(\n","        (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","      (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    )\n","    (1): UnetResBlock(\n","      (conv1): Convolution(\n","        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      )\n","      (conv2): Convolution(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv3): Convolution(\n","        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","      (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    )\n","  )\n","  (bottleneck): UnetResBlock(\n","    (conv1): Convolution(\n","      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    )\n","    (conv2): Convolution(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv3): Convolution(\n","      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","    )\n","    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","    (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (norm3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","  )\n","  (upsamples): ModuleList(\n","    (0): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","    (1): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","    (2): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","  )\n","  (output_block): UnetOutBlock(\n","    (conv): Convolution(\n","      (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (skip_layers): DynUNetSkipLayer(\n","    (downsample): UnetResBlock(\n","      (conv1): Convolution(\n","        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv2): Convolution(\n","        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (conv3): Convolution(\n","        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","      (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      (norm3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    )\n","    (next_layer): DynUNetSkipLayer(\n","      (downsample): UnetResBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv3): Convolution(\n","          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","      (next_layer): DynUNetSkipLayer(\n","        (downsample): UnetResBlock(\n","          (conv1): Convolution(\n","            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          )\n","          (conv2): Convolution(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (conv3): Convolution(\n","            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          )\n","          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","          (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","        (next_layer): UnetResBlock(\n","          (conv1): Convolution(\n","            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          )\n","          (conv2): Convolution(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (conv3): Convolution(\n","            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          )\n","          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","          (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","        (upsample): UnetUpBlock(\n","          (transp_conv): Convolution(\n","            (conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (conv_block): UnetBasicBlock(\n","            (conv1): Convolution(\n","              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            )\n","            (conv2): Convolution(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            )\n","            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","            (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","            (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          )\n","        )\n","      )\n","      (upsample): UnetUpBlock(\n","        (transp_conv): Convolution(\n","          (conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","        )\n","        (conv_block): UnetBasicBlock(\n","          (conv1): Convolution(\n","            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (conv2): Convolution(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","          (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","          (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        )\n","      )\n","    )\n","    (upsample): UnetUpBlock(\n","      (transp_conv): Convolution(\n","        (conv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (conv_block): UnetBasicBlock(\n","        (conv1): Convolution(\n","          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (conv2): Convolution(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n","        (norm1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","        (norm2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# import shutil\n","# shutil.rmtree(\"/content/drive/MyDrive/Deep Learning/prediction0525\")"],"metadata":{"id":"vROC9BoVUYr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    for test_data in pred_loader:\n","        test_images= test_data[\"img\"].to(device)\n","        # define sliding window size and batch size for windows inference\n","        roi_size = (1696, 928)\n","        sw_batch_size = 2\n","        test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n","\n","        # visualize( \n","        #     image=test_images[0].cpu().permute(1,2,0),             \n","        #     predicted_mask=test_outputs[0].squeeze().cpu().numpy().round()\n","        # )                   \n","        #saverIM(test_images[0].cpu())        \n","        saverPD(test_outputs[0].cpu())\n","        \n","        test_outputs = [post_trans(i) for i in decollate_batch(test_outputs)]  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PNBYW1EJ3xfo","outputId":"a6578541-9ae6-43d8-9fb1-16212d309546","executionInfo":{"status":"ok","timestamp":1653593425473,"user_tz":-480,"elapsed":59474,"user":{"displayName":"陳芃辰","userId":"02611031122482173001"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["file written: prediction0526_2/0_PD.png.\n","file written: prediction0526_2/1_PD.png.\n","file written: prediction0526_2/2_PD.png.\n","file written: prediction0526_2/3_PD.png.\n","file written: prediction0526_2/4_PD.png.\n","file written: prediction0526_2/5_PD.png.\n","file written: prediction0526_2/6_PD.png.\n","file written: prediction0526_2/7_PD.png.\n","file written: prediction0526_2/8_PD.png.\n","file written: prediction0526_2/9_PD.png.\n","file written: prediction0526_2/10_PD.png.\n","file written: prediction0526_2/11_PD.png.\n","file written: prediction0526_2/12_PD.png.\n","file written: prediction0526_2/13_PD.png.\n","file written: prediction0526_2/14_PD.png.\n","file written: prediction0526_2/15_PD.png.\n","file written: prediction0526_2/16_PD.png.\n","file written: prediction0526_2/17_PD.png.\n","file written: prediction0526_2/18_PD.png.\n","file written: prediction0526_2/19_PD.png.\n","file written: prediction0526_2/20_PD.png.\n","file written: prediction0526_2/21_PD.png.\n","file written: prediction0526_2/22_PD.png.\n","file written: prediction0526_2/23_PD.png.\n","file written: prediction0526_2/24_PD.png.\n","file written: prediction0526_2/25_PD.png.\n","file written: prediction0526_2/26_PD.png.\n","file written: prediction0526_2/27_PD.png.\n","file written: prediction0526_2/28_PD.png.\n","file written: prediction0526_2/29_PD.png.\n","file written: prediction0526_2/30_PD.png.\n","file written: prediction0526_2/31_PD.png.\n","file written: prediction0526_2/32_PD.png.\n","file written: prediction0526_2/33_PD.png.\n","file written: prediction0526_2/34_PD.png.\n","file written: prediction0526_2/35_PD.png.\n","file written: prediction0526_2/36_PD.png.\n","file written: prediction0526_2/37_PD.png.\n","file written: prediction0526_2/38_PD.png.\n","file written: prediction0526_2/39_PD.png.\n","file written: prediction0526_2/40_PD.png.\n","file written: prediction0526_2/41_PD.png.\n","file written: prediction0526_2/42_PD.png.\n","file written: prediction0526_2/43_PD.png.\n","file written: prediction0526_2/44_PD.png.\n","file written: prediction0526_2/45_PD.png.\n","file written: prediction0526_2/46_PD.png.\n","file written: prediction0526_2/47_PD.png.\n","file written: prediction0526_2/48_PD.png.\n","file written: prediction0526_2/49_PD.png.\n","file written: prediction0526_2/50_PD.png.\n","file written: prediction0526_2/51_PD.png.\n","file written: prediction0526_2/52_PD.png.\n","file written: prediction0526_2/53_PD.png.\n","file written: prediction0526_2/54_PD.png.\n","file written: prediction0526_2/55_PD.png.\n","file written: prediction0526_2/56_PD.png.\n","file written: prediction0526_2/57_PD.png.\n","file written: prediction0526_2/58_PD.png.\n","file written: prediction0526_2/59_PD.png.\n","file written: prediction0526_2/60_PD.png.\n","file written: prediction0526_2/61_PD.png.\n","file written: prediction0526_2/62_PD.png.\n","file written: prediction0526_2/63_PD.png.\n","file written: prediction0526_2/64_PD.png.\n","file written: prediction0526_2/65_PD.png.\n","file written: prediction0526_2/66_PD.png.\n","file written: prediction0526_2/67_PD.png.\n","file written: prediction0526_2/68_PD.png.\n","file written: prediction0526_2/69_PD.png.\n","file written: prediction0526_2/70_PD.png.\n","file written: prediction0526_2/71_PD.png.\n","file written: prediction0526_2/72_PD.png.\n","file written: prediction0526_2/73_PD.png.\n","file written: prediction0526_2/74_PD.png.\n","file written: prediction0526_2/75_PD.png.\n","file written: prediction0526_2/76_PD.png.\n","file written: prediction0526_2/77_PD.png.\n","file written: prediction0526_2/78_PD.png.\n","file written: prediction0526_2/79_PD.png.\n","file written: prediction0526_2/80_PD.png.\n","file written: prediction0526_2/81_PD.png.\n","file written: prediction0526_2/82_PD.png.\n","file written: prediction0526_2/83_PD.png.\n","file written: prediction0526_2/84_PD.png.\n","file written: prediction0526_2/85_PD.png.\n","file written: prediction0526_2/86_PD.png.\n","file written: prediction0526_2/87_PD.png.\n","file written: prediction0526_2/88_PD.png.\n","file written: prediction0526_2/89_PD.png.\n","file written: prediction0526_2/90_PD.png.\n","file written: prediction0526_2/91_PD.png.\n","file written: prediction0526_2/92_PD.png.\n","file written: prediction0526_2/93_PD.png.\n","file written: prediction0526_2/94_PD.png.\n","file written: prediction0526_2/95_PD.png.\n","file written: prediction0526_2/96_PD.png.\n","file written: prediction0526_2/97_PD.png.\n","file written: prediction0526_2/98_PD.png.\n","file written: prediction0526_2/99_PD.png.\n","file written: prediction0526_2/100_PD.png.\n","file written: prediction0526_2/101_PD.png.\n","file written: prediction0526_2/102_PD.png.\n","file written: prediction0526_2/103_PD.png.\n","file written: prediction0526_2/104_PD.png.\n","file written: prediction0526_2/105_PD.png.\n","file written: prediction0526_2/106_PD.png.\n","file written: prediction0526_2/107_PD.png.\n","file written: prediction0526_2/108_PD.png.\n","file written: prediction0526_2/109_PD.png.\n","file written: prediction0526_2/110_PD.png.\n","file written: prediction0526_2/111_PD.png.\n","file written: prediction0526_2/112_PD.png.\n","file written: prediction0526_2/113_PD.png.\n","file written: prediction0526_2/114_PD.png.\n","file written: prediction0526_2/115_PD.png.\n","file written: prediction0526_2/116_PD.png.\n","file written: prediction0526_2/117_PD.png.\n","file written: prediction0526_2/118_PD.png.\n","file written: prediction0526_2/119_PD.png.\n","file written: prediction0526_2/120_PD.png.\n","file written: prediction0526_2/121_PD.png.\n","file written: prediction0526_2/122_PD.png.\n","file written: prediction0526_2/123_PD.png.\n","file written: prediction0526_2/124_PD.png.\n","file written: prediction0526_2/125_PD.png.\n","file written: prediction0526_2/126_PD.png.\n","file written: prediction0526_2/127_PD.png.\n","file written: prediction0526_2/128_PD.png.\n","file written: prediction0526_2/129_PD.png.\n","file written: prediction0526_2/130_PD.png.\n"]}]},{"cell_type":"code","source":["import glob\n","prediction_path = glob.glob(\"/content/drive/MyDrive/Deep Learning/prediction0525/*\")\n","\n","image_name = os.path.basename(prediction_path[0])\n","new_name = image_name.split(\"_\")[0].rjust(8,\"0\")"],"metadata":{"id":"y3U5Xcx9tjDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","import shutil\n","prediction_path = glob.glob(\"/content/drive/MyDrive/Deep Learning/prediction0526_2/*\")\n","\n","dest_path = \"/content/drive/MyDrive/Deep Learning/prediction0526_2/0526_2/\"\n","os.makedirs(dest_path)\n","for path in prediction_path:\n","  image_name = os.path.basename(path)\n","  new_name = image_name.split(\"_\")[0].rjust(8, \"0\")\n","  # new_name = new_name.rjust(8, \"0\")\n","  new_name = \"Public_\" + new_name + \".png\"\n","  new_path = os.path.join(dest_path, new_name)\n","  shutil.copy(path , new_path)"],"metadata":{"id":"XB38JrL9-GMa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zhfPOtoUuBN5"},"execution_count":null,"outputs":[]}]}